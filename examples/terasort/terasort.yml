!benchmark
id: 8
name: TeraSort
rounds: 1
endable: false

providers:
 - &ec2 !provider
    name: aws-ec2
    credentialPath: AwsCredentials.properties

#tipos de instancia oferecidas pelo provedores de nuvem
virtualMachineTypes:    
 - &m3_medium !virtualMachineType
    providerProfile: m3.medium
    provider: *ec2

scriptlets:
 - &confighosts !scriptlet
   id: 1
   scripts:
    - 'sudo -s sed -i "s;^.* hadoopmaster;${scenarioScope.metric(master).privateIpAddress} hadoopmaster;g" /etc/hosts'
    - 'sudo -s sed -i "s;^.* hadoopslave01;${scenarioScope.metric(slave).privateIpAddress} hadoopslave01;g" /etc/hosts'
    - '~/start_metric.sh 10.142.201.15'
 - &stop_metric !scriptlet
   id: 2
   scripts:
    - "ps -aux | grep go | grep hadoop | awk '{print $2}' | xargs kill -9"
    - "ps -aux | grep tail | awk '{print $2}' | xargs kill -9"
 - &submit !scriptlet
   id: 3
   scripts:
    - '~/start.sh'
 - &start_crawler !scriptlet
   id: 4
   scripts:
    - 'sudo nohup docker-compose -f /home/ubuntu/go/src/github.com/mathcunha/gomonitor/docker-compose.yml start &'

virtualMachines:
 - &master !virtualMachine
   id: 2
   providerId: us-east-1/i-81bd3b54
   type: *m3_medium
   name: master
   scripts:
    start_metric : *confighosts
    stop_metric: *stop_metric
    submit_workload : *submit
 - &slave !virtualMachine
   id: 3
   providerId: us-east-1/i-09da5bdc
   type: *m3_medium
   name: slave
   scripts:
    start_metric : *confighosts
    stop_metric : *stop_metric

workloads:
 - &terasort !workload
  targets:
   - *master
  functions:
   - !workloadFunction
    values: "1000000"

scenarios:
  - !scenario
    name: 1_m3_medium
    id: 1
    endable: false
    workload: *terasort
    metric:
      slave : *slave
      master : *master
